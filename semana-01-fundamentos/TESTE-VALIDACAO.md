# ğŸ§ª Teste de ValidaÃ§Ã£o - Semana 1: Fundamentos de IA/ML

## â±ï¸ Tempo estimado: 15 minutos

---

## ğŸ“‹ Parte 1: Conceitos Fundamentais (mÃºltipla escolha)

### QuestÃ£o 1: Tipos de Machine Learning
VocÃª precisa criar um sistema que identifica se um e-mail Ã© spam ou nÃ£o spam. Qual tipo de ML vocÃª usaria?

**A)** Aprendizado NÃ£o-Supervisionado  
**B)** Aprendizado Supervisionado  
**C)** Aprendizado por ReforÃ§o  
**D)** NÃ£o Ã© possÃ­vel com ML  

<details>
<summary>ğŸ’¡ Ver resposta</summary>

**Resposta: B) Aprendizado Supervisionado**

**Por quÃª:**
- O problema tem **labels claros** (spam ou nÃ£o-spam)
- VocÃª tem **exemplos rotulados** para treinar
- O objetivo Ã© **classificar** novos e-mails

**Aprendizado Supervisionado:**
- Requer dados rotulados (X â†’ y)
- Usado para classificaÃ§Ã£o e regressÃ£o
- Exemplos: spam detection, previsÃ£o de preÃ§os, diagnÃ³stico mÃ©dico

**Quando usar cada tipo:**
- **Supervisionado:** Tenho labels (spam/nÃ£o-spam, preÃ§o, doenÃ§a/saudÃ¡vel)
- **NÃ£o-Supervisionado:** NÃ£o tenho labels (agrupar clientes similares)
- **ReforÃ§o:** DecisÃµes sequenciais (jogo, robÃ³tica, trading)

**Conceito-chave:** Se vocÃª tem a "resposta certa" nos dados de treino, Ã© supervisionado!
</details>

---

### QuestÃ£o 2: Features e Target
VocÃª tem este dataset de casas:

```python
import pandas as pd

df = pd.DataFrame({
    'area': [100, 150, 80, 200],
    'quartos': [2, 3, 2, 4],
    'idade': [5, 10, 2, 15],
    'preco': [300000, 450000, 250000, 600000]
})
```

Se vocÃª quer **prever o preÃ§o**, o que sÃ£o as **features** e o que Ã© o **target**?

**A)** Features: preco | Target: area, quartos, idade  
**B)** Features: area, quartos, idade | Target: preco  
**C)** Features: area, quartos | Target: idade, preco  
**D)** Todas sÃ£o features  

<details>
<summary>ğŸ’¡ Ver resposta</summary>

**Resposta: B) Features: area, quartos, idade | Target: preco**

**Por quÃª:**

**Features (X):**
- SÃ£o as **variÃ¡veis independentes**
- InformaÃ§Ãµes que vocÃª **TEM** sobre o problema
- Usadas para **fazer a previsÃ£o**
- No exemplo: `area`, `quartos`, `idade`

**Target (y):**
- Ã‰ a **variÃ¡vel dependente**
- O que vocÃª **QUER PREVER**
- No exemplo: `preco`

**CÃ³digo correto:**
```python
# Separar features e target
X = df[['area', 'quartos', 'idade']]  # Features
y = df['preco']                        # Target

# Ou usando drop:
X = df.drop('preco', axis=1)  # Remove o target
y = df['preco']                # Pega apenas o target
```

**Conceito-chave:** 
- **Features = O que vocÃª usa para prever**
- **Target = O que vocÃª quer prever**

**Analogia:**
```
PrevisÃ£o do tempo:
Features: temperatura de ontem, umidade, pressÃ£o
Target: vai chover hoje? (sim/nÃ£o)
```
</details>

---

### QuestÃ£o 3: Train/Test Split
Por que dividimos os dados em treino e teste?

**A)** Para o modelo treinar mais rÃ¡pido  
**B)** Para economizar memÃ³ria  
**C)** Para avaliar se o modelo generaliza para dados novos  
**D)** Para visualizar os dados melhor  

<details>
<summary>ğŸ’¡ Ver resposta</summary>

**Resposta: C) Para avaliar se o modelo generaliza para dados novos**

**Por quÃª:**

**O Problema:**
```python
# Se treinar e testar nos MESMOS dados:
model.fit(X, y)           # Treina com todos os dados
score = model.score(X, y) # Testa nos mesmos dados = 100%! ğŸ˜±

# Mas o modelo pode ter DECORADO, nÃ£o APRENDIDO!
```

**A SoluÃ§Ã£o:**
```python
# Dividir em treino e teste:
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

model.fit(X_train, y_train)        # Treina com 80%
score = model.score(X_test, y_test) # Testa com 20% nunca vistos
```

**Analogia:**
```
âŒ Estudar as respostas da prova antes de fazer
   = 100% de nota, mas nÃ£o aprendeu!

âœ… Estudar com exercÃ­cios A, fazer prova com exercÃ­cios B
   = Nota real mostra se realmente aprendeu
```

**ProporÃ§Ãµes comuns:**
- **80-20:** PadrÃ£o (80% treino, 20% teste)
- **70-30:** Dataset mÃ©dio
- **90-10:** Dataset muito pequeno

**Conceito-chave:** Test set simula dados do "mundo real" que o modelo nunca viu!
</details>

---

### QuestÃ£o 4: Overfitting vs Underfitting
Observe estes resultados:

**Modelo A:**
- Train accuracy: 99%
- Test accuracy: 60%

**Modelo B:**
- Train accuracy: 65%
- Test accuracy: 63%

**Modelo C:**
- Train accuracy: 85%
- Test accuracy: 82%

Qual modelo estÃ¡ em overfitting? Qual em underfitting? Qual estÃ¡ bom?

**A)** Overfitting: A | Underfitting: B | Bom: C  
**B)** Overfitting: B | Underfitting: A | Bom: C  
**C)** Overfitting: C | Underfitting: A | Bom: B  
**D)** Todos estÃ£o em overfitting  

<details>
<summary>ğŸ’¡ Ver resposta</summary>

**Resposta: A) Overfitting: A | Underfitting: B | Bom: C**

**AnÃ¡lise Detalhada:**

### ğŸ”´ Modelo A - OVERFITTING
```
Train: 99% | Test: 60%
DiferenÃ§a: 39% â† MUITO ALTO!
```
**Problema:** Modelo **decorou** os dados de treino, nÃ£o generalizou.

**Sintomas:**
- Train accuracy muito alta
- Test accuracy muito baixa
- Grande diferenÃ§a entre train e test (>15%)

**Causa:**
- Modelo muito complexo
- Muitas features irrelevantes
- Poucos dados de treino

**SoluÃ§Ã£o:**
```python
# Simplificar o modelo
RandomForestClassifier(
    max_depth=5,           # Limita profundidade
    min_samples_split=20   # Exige mais dados para dividir
)

# Ou adicionar mais dados de treino
```

---

### ğŸŸ¡ Modelo B - UNDERFITTING
```
Train: 65% | Test: 63%
Ambos baixos!
```
**Problema:** Modelo muito **simples**, nÃ£o captura padrÃµes.

**Sintomas:**
- Train accuracy baixa
- Test accuracy baixa
- DiferenÃ§a pequena (modelo consistente, mas ruim)

**Causa:**
- Modelo muito simples
- Poucas features
- Features nÃ£o informativas

**SoluÃ§Ã£o:**
```python
# Aumentar complexidade
RandomForestClassifier(
    max_depth=15,          # Permite mais profundidade
    n_estimators=200       # Mais Ã¡rvores
)

# Ou adicionar mais features relevantes
```

---

### ğŸŸ¢ Modelo C - BOM (IDEAL)
```
Train: 85% | Test: 82%
DiferenÃ§a: 3% â† BOM!
```
**Resultado:** Modelo generaliza bem!

**CaracterÃ­sticas:**
- Train e Test prÃ³ximos (diferenÃ§a <5-10%)
- Accuracies razoÃ¡veis (>80% depende do problema)
- Modelo equilibrado

---

### ğŸ“Š Resumo Visual:

```
                 Train  Test  DiferenÃ§a  DiagnÃ³stico
Modelo A (âŒ)    99%    60%   39%        Overfitting
Modelo B (âš ï¸)    65%    63%   2%         Underfitting
Modelo C (âœ…)    85%    82%   3%         Bom!
```

**Conceito-chave:** Busque **equilÃ­brio** entre train e test!
</details>

---

## ğŸ–¥ï¸ Parte 2: PrÃ¡tica (cÃ³digo)

### Desafio: Primeiro Pipeline ML

Complete o cÃ³digo abaixo com as partes que faltam:

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Carregar dados
df = pd.read_csv('titanic.csv')

# Selecionar apenas colunas numÃ©ricas para simplificar
X = df[['age', 'fare', 'pclass']].fillna(0)
y = df['survived']

# PREENCHA: Dividir em treino e teste (80-20)
X_train, X_test, y_train, y_test = ________________

# PREENCHA: Criar modelo Random Forest
model = ________________

# PREENCHA: Treinar o modelo
________________

# PREENCHA: Fazer previsÃµes
y_pred = ________________

# Avaliar
accuracy = accuracy_score(y_test, y_pred)
print(f"AcurÃ¡cia: {accuracy:.2%}")
```

<details>
<summary>ğŸ’¡ Ver resposta completa</summary>

### âœ… CÃ³digo Completo e Correto:

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Carregar dados
df = pd.read_csv('titanic.csv')

# Selecionar apenas colunas numÃ©ricas para simplificar
X = df[['age', 'fare', 'pclass']].fillna(0)
y = df['survived']

# 1ï¸âƒ£ Dividir em treino e teste (80-20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,      # 20% para teste
    random_state=42     # Reprodutibilidade
)

# 2ï¸âƒ£ Criar modelo Random Forest
model = RandomForestClassifier(
    n_estimators=100,   # 100 Ã¡rvores
    random_state=42     # Reprodutibilidade
)

# 3ï¸âƒ£ Treinar o modelo
model.fit(X_train, y_train)

# 4ï¸âƒ£ Fazer previsÃµes
y_pred = model.predict(X_test)

# Avaliar
accuracy = accuracy_score(y_test, y_pred)
print(f"AcurÃ¡cia: {accuracy:.2%}")
```

---

### ğŸ“ ExplicaÃ§Ã£o Linha por Linha:

#### 1ï¸âƒ£ Train/Test Split
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y,              # Features e target
    test_size=0.2,     # 20% teste, 80% treino
    random_state=42    # Seed para reproduzir resultados
)
```
**Por quÃª `random_state=42`?**
- Garante que a divisÃ£o seja sempre igual
- Facilita comparar resultados
- Qualquer nÃºmero serve (42 Ã© tradicional)

---

#### 2ï¸âƒ£ Criar Modelo
```python
model = RandomForestClassifier(
    n_estimators=100,   # Quantas Ã¡rvores criar
    random_state=42     # Reprodutibilidade
)
```
**Alternativas:**
```python
# Outros modelos comuns:
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier

model = LogisticRegression(random_state=42)
model = DecisionTreeClassifier(random_state=42)
```

---

#### 3ï¸âƒ£ Treinar
```python
model.fit(X_train, y_train)
```
**O que acontece:**
- Modelo analisa `X_train` (features)
- Aprende padrÃµes que levam a `y_train` (target)
- Ajusta parÃ¢metros internos

**âš ï¸ NUNCA use X_test aqui!**

---

#### 4ï¸âƒ£ Prever
```python
y_pred = model.predict(X_test)
```
**O que retorna:**
- Array com previsÃµes: `[0, 1, 1, 0, ...]`
- Um valor para cada linha de `X_test`
- 0 = nÃ£o sobreviveu, 1 = sobreviveu

**Verificar:**
```python
print(f"PrevisÃµes: {y_pred[:5]}")        # [0 1 1 0 1]
print(f"Valores reais: {y_test[:5]}")    # [0 1 0 0 1]
```

---

### ğŸ¯ Checklist de ValidaÃ§Ã£o:

| Passo | DescriÃ§Ã£o | Dados Usados |
|-------|-----------|--------------|
| 1. Split | Dividir dados | X, y â†’ train/test |
| 2. Create | Criar modelo | - |
| 3. Fit | Treinar | X_train, y_train |
| 4. Predict | Prever | X_test |
| 5. Evaluate | Avaliar | y_test vs y_pred |

**âš ï¸ Regra de Ouro:**
```
Treino: usa apenas _train
Teste: usa apenas _test
NUNCA misture!
```

</details>

---

## ğŸ“Š Parte 3: AnÃ¡lise de Dados

VocÃª tem este resultado de `.describe()`:

```python
df[['age', 'fare']].describe()
```

```
              age        fare
count    891.00     891.00
mean      29.70      32.20
std       14.53      49.69
min        0.42       0.00
25%       20.12       7.91
50%       28.00      14.45
75%       38.00      31.00
max       80.00     512.33
```

### QuestÃ£o: O que vocÃª pode concluir sobre `age` e `fare`?

<details>
<summary>ğŸ’¡ Ver resposta e anÃ¡lise</summary>

### ğŸ“Š AnÃ¡lise Detalhada:

#### ğŸ” Coluna `age` (Idade):

**ObservaÃ§Ãµes:**
- **MÃ©dia:** 29.7 anos (populaÃ§Ã£o jovem/adulta)
- **Mediana (50%):** 28 anos (similar Ã  mÃ©dia = distribuiÃ§Ã£o simÃ©trica)
- **Desvio padrÃ£o:** 14.5 anos (variaÃ§Ã£o moderada)
- **Range:** 0.42 a 80 anos (bebÃªs a idosos)

**InterpretaÃ§Ã£o:**
```
âœ… DistribuiÃ§Ã£o relativamente normal
âœ… Sem outliers extremos
âœ… Idade variada (boa diversidade)
```

**VisualizaÃ§Ã£o mental:**
```
   |
   |    *****
   |   *******
   |  *********
   | ***********
   |_____________
   0  20  40  60  80
      (distribuiÃ§Ã£o normal)
```

---

#### ğŸ” Coluna `fare` (Tarifa):

**ObservaÃ§Ãµes:**
- **MÃ©dia:** 32.2
- **Mediana (50%):** 14.45 (MUITO MENOR que mÃ©dia!)
- **Desvio padrÃ£o:** 49.7 (MAIOR que a mÃ©dia! ğŸ˜±)
- **Max:** 512.33 (16x a mÃ©dia!)

**InterpretaÃ§Ã£o:**
```
âš ï¸ DistribuiÃ§Ã£o ASSIMÃ‰TRICA (skewed)
âš ï¸ PresenÃ§a de OUTLIERS (valores muito altos)
âš ï¸ Mediana << MÃ©dia indica assimetria Ã  direita
```

**VisualizaÃ§Ã£o mental:**
```
   |*
   |**
   |***
   |****
   |*****
   |********          *
   |__________________|_____
   0    50   100  200  512
   (muitos valores baixos, poucos muito altos)
```

---

### ğŸ¯ ConclusÃµes PrÃ¡ticas:

#### 1. **Mediana vs MÃ©dia**
```python
# Quando usar cada uma:

# age: mÃ©dia â‰ˆ mediana (29.7 vs 28)
# â†’ Usar MÃ‰DIA para anÃ¡lises

# fare: mÃ©dia >> mediana (32.2 vs 14.45)
# â†’ Usar MEDIANA (mais representativa!)
```

**Por quÃª fare tem essa diferenÃ§a?**
- Maioria pagou tarifas baixas (classes 2 e 3)
- Poucos pagaram tarifas muito altas (classe 1, suÃ­tes)
- Outliers "puxam" a mÃ©dia para cima

---

#### 2. **Outliers**
```python
# Detectar outliers em fare:
Q1 = 7.91    # 25%
Q3 = 31.00   # 75%
IQR = Q3 - Q1 = 23.09

upper_bound = Q3 + 1.5 * IQR = 31 + 34.6 = 65.6

# Valores > 65.6 sÃ£o outliers
# Max = 512.33 â†’ Definitivamente outlier!
```

---

#### 3. **NormalizaÃ§Ã£o**
```python
# fare precisa de normalizaÃ§Ã£o para alguns modelos:
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df['fare_scaled'] = scaler.fit_transform(df[['fare']])

# age pode nÃ£o precisar (distribuiÃ§Ã£o mais normal)
```

---

### ğŸ“‹ Checklist de AnÃ¡lise `.describe()`:

Ao analisar `.describe()`, observe:

- [ ] **Count:** Tem dados faltantes? (count < total de linhas)
- [ ] **Mean vs Median:** SÃ£o prÃ³ximos? (normal) ou distantes? (assimÃ©trico)
- [ ] **Std:** Ã‰ alto? (muita variaÃ§Ã£o) ou baixo? (dados homogÃªneos)
- [ ] **Min/Max:** Tem valores impossÃ­veis? (idade negativa, salÃ¡rio 0)
- [ ] **Quartis:** DistribuiÃ§Ã£o uniforme ou concentrada?

---

### ğŸ¨ VisualizaÃ§Ãµes Ãšteis:

```python
import matplotlib.pyplot as plt

# Comparar age vs fare
fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# Age: distribuiÃ§Ã£o normal
axes[0].hist(df['age'], bins=30, edgecolor='black')
axes[0].set_title('Age (DistribuiÃ§Ã£o Normal)')

# Fare: assimÃ©trica com outliers
axes[1].hist(df['fare'], bins=30, edgecolor='black')
axes[1].set_title('Fare (AssimÃ©trica com Outliers)')

plt.tight_layout()
plt.show()
```

**Conceito-chave:** `.describe()` revela problemas antes do modelo!

</details>

---

## ğŸ“ Gabarito de Auto-AvaliaÃ§Ã£o

### PontuaÃ§Ã£o:

- **Parte 1 (Conceitos):** 4 questÃµes Ã— 2.5 pontos = **10 pontos**
- **Parte 2 (CÃ³digo):** 1 exercÃ­cio Ã— 5 pontos = **5 pontos**  
- **Parte 3 (AnÃ¡lise):** 1 questÃ£o Ã— 5 pontos = **5 pontos**

**TOTAL:** 20 pontos

---

### ğŸ“Š InterpretaÃ§Ã£o da sua nota:

#### ğŸ† 17-20 pontos: EXCELENTE!
**VocÃª dominou os fundamentos!**

âœ… Entende tipos de ML  
âœ… Sabe separar features e target  
âœ… Compreende train/test split  
âœ… Identifica overfitting/underfitting  

**PrÃ³ximos passos:**
- âœ… AVANÃ‡AR para Semana 2 com confianÃ§a!
- Considere revisar rapidamente os pontos que errou

---

#### ğŸ’ª 13-16 pontos: BOM!
**VocÃª entende o bÃ¡sico, mas pode reforÃ§ar alguns conceitos.**

âœ… Conceitos principais estÃ£o claros  
âš ï¸ Alguns detalhes precisam de atenÃ§Ã£o  

**PrÃ³ximos passos:**
- Revise as questÃµes que errou
- Execute novamente o notebook da Semana 1
- Pode avanÃ§ar para Semana 2, mas consulte o material S1 quando necessÃ¡rio

---

#### ğŸ”„ 9-12 pontos: PARCIAL
**Recomendado revisar alguns conceitos antes de avanÃ§ar.**

âš ï¸ Conceitos fundamentais nÃ£o estÃ£o totalmente claros  
âš ï¸ Pode ter dificuldade na Semana 2  

**PrÃ³ximos passos:**
- RefaÃ§a os notebooks da Semana 1
- Foque nos conceitos que errou aqui
- FaÃ§a o teste novamente apÃ³s 2 dias
- Avance quando se sentir mais confiante

---

#### ğŸ“š 0-8 pontos: REVISAR
**Ã‰ importante reforÃ§ar os fundamentos da Semana 1.**

âŒ Conceitos base precisam de mais atenÃ§Ã£o  

**PrÃ³ximos passos:**
1. **NÃ£o desanime!** ML Ã© complexo no inÃ­cio
2. Releia a documentaÃ§Ã£o da Semana 1
3. Execute cada cÃ©lula do notebook com atenÃ§Ã£o
4. Anote os conceitos principais com suas palavras
5. Retome este teste em 1 semana

**Lembre-se:** Fundamentos sÃ³lidos = sucesso no futuro!

---

## ğŸ¯ ReflexÃ£o Final

Responda honestamente (sÃ³ para vocÃª):

1. **Sei diferenciar Supervisionado de NÃ£o-Supervisionado?**  
   [ ] Sim [ ] Mais ou menos [ ] Preciso revisar  

2. **Entendo por que dividir em train/test?**  
   [ ] Sim [ ] Mais ou menos [ ] Preciso revisar  

3. **Consigo identificar overfitting?**  
   [ ] Sim [ ] Mais ou menos [ ] Preciso revisar  

4. **Me sinto confortÃ¡vel para fazer um pipeline bÃ¡sico?**  
   [ ] Sim [ ] Com ajuda [ ] Ainda nÃ£o  

---

## âœ… DecisÃ£o Final

### â¡ï¸ AVANCE para Semana 2 se:
- Acertou 13+ pontos
- Respondeu "Sim" ou "Mais ou menos" na maioria das reflexÃµes
- Sente que entende os conceitos principais

### ğŸ”„ REVISE Semana 1 se:
- Acertou <9 pontos
- Respondeu "Preciso revisar" em 3+ reflexÃµes
- Sente que os conceitos ainda estÃ£o confusos

---

## ğŸ’¡ Dica Final

Os fundamentos da Semana 1 sÃ£o a **BASE de tudo** que vem depois:

```
Semana 1: Fundamentos
    â†“
Semana 2: Data Science (usa train/test, features)
    â†“
Semana 3: ML AvanÃ§ado (usa overfitting, modelos)
    â†“
...
```

**Invista tempo aqui = Facilita TUDO que vem depois!** ğŸ¯

---

**Sucesso! VocÃª estÃ¡ construindo uma base sÃ³lida! ğŸš€**

_Este teste pode ser refeito sempre que quiser. Use-o como ferramenta de aprendizado!_
