# ğŸ“Š Machine Learning Cheatsheet - Python & Scikit-learn

**Guia RÃ¡pido de ReferÃªncia | 4 PÃ¡ginas para ImpressÃ£o**

---

## ğŸ“¦ PÃGINA 1: IMPORTAÃ‡Ã•ES E CARREGAMENTO DE DADOS

### ğŸ”§ Imports Essenciais

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# 1. MANIPULAÃ‡ÃƒO DE DADOS
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
import pandas as pd                # DataFrames e anÃ¡lise
import numpy as np                 # Arrays e matemÃ¡tica

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# 2. VISUALIZAÃ‡ÃƒO
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
import matplotlib.pyplot as plt    # GrÃ¡ficos bÃ¡sicos
import seaborn as sns              # GrÃ¡ficos estatÃ­sticos

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# 3. PRÃ‰-PROCESSAMENTO
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
from sklearn.model_selection import train_test_split  # Dividir dados
from sklearn.preprocessing import StandardScaler      # Normalizar
from sklearn.preprocessing import OneHotEncoder       # Encoding

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# 4. MODELOS DE CLASSIFICAÃ‡ÃƒO
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
from sklearn.tree import DecisionTreeClassifier       # Ãrvore
from sklearn.ensemble import RandomForestClassifier   # Random Forest
from sklearn.svm import SVC                           # SVM
from sklearn.neural_network import MLPClassifier      # Neural Network
from xgboost import XGBClassifier                     # XGBoost

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# 5. MÃ‰TRICAS
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
from sklearn.metrics import (
    accuracy_score,           # AcurÃ¡cia
    precision_score,          # PrecisÃ£o
    recall_score,             # Recall
    f1_score,                 # F1-Score
    confusion_matrix,         # Matriz de ConfusÃ£o
    classification_report,    # RelatÃ³rio completo
    roc_auc_score,           # ROC-AUC
    roc_curve                # Curva ROC
)
```

---

### ğŸ“‚ Carregamento de Dados

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# CARREGAR CSV
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
df = pd.read_csv('dataset.csv')

# OpÃ§Ãµes Ãºteis:
df = pd.read_csv('dataset.csv', 
                 encoding='utf-8',      # Encoding
                 sep=',',               # Separador
                 index_col=0)           # Coluna como Ã­ndice

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# EXPLORAÃ‡ÃƒO RÃPIDA
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
df.head()                    # Primeiras 5 linhas
df.tail()                    # Ãšltimas 5 linhas
df.shape                     # (linhas, colunas)
df.info()                    # Tipos e memÃ³ria
df.describe()                # EstatÃ­sticas numÃ©ricas
df.columns                   # Nomes das colunas
df.dtypes                    # Tipos de cada coluna
df.isnull().sum()           # Valores faltantes por coluna
df['coluna'].value_counts() # Contagem de valores Ãºnicos
```

---

### ğŸ” EDA - AnÃ¡lise ExploratÃ³ria

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# CORRELAÃ‡ÃƒO
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
correlation = df.corr()

# Heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0)
plt.title('Matriz de CorrelaÃ§Ã£o')
plt.show()

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# DISTRIBUIÃ‡Ã•ES
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
df['coluna'].hist(bins=30)                    # Histograma
df['coluna'].plot(kind='box')                 # Boxplot
sns.countplot(x='coluna', data=df)           # Contagem

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# RELAÃ‡Ã•ES ENTRE VARIÃVEIS
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
sns.scatterplot(x='col1', y='col2', hue='target', data=df)
sns.pairplot(df, hue='target')               # MÃºltiplas relaÃ§Ãµes
```

---

## ğŸ§¹ PÃGINA 2: PRÃ‰-PROCESSAMENTO

### ğŸ”„ Tratamento de Dados Faltantes

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# IDENTIFICAR
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
df.isnull().sum()                    # Quantidade por coluna
df.isnull().sum() / len(df) * 100   # Porcentagem

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# REMOVER
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
df.dropna(inplace=True)              # Remove linhas com NaN
df.dropna(subset=['col'], inplace=True)  # Remove NaN de coluna especÃ­fica
df.drop('coluna', axis=1, inplace=True)  # Remove coluna inteira

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# PREENCHER (IMPUTAÃ‡ÃƒO)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
df['col'].fillna(df['col'].mean(), inplace=True)     # MÃ©dia
df['col'].fillna(df['col'].median(), inplace=True)   # Mediana
df['col'].fillna(0, inplace=True)                    # Valor fixo
df['col'].fillna(method='ffill', inplace=True)       # Forward fill

# Por grupo
df['age'] = df.groupby('sex')['age'].transform(
    lambda x: x.fillna(x.median())
)
```

---

### ğŸ·ï¸ Encoding de VariÃ¡veis CategÃ³ricas

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ONE-HOT ENCODING (variÃ¡veis nominais)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Exemplo: sex = ['male', 'female']
df = pd.get_dummies(df, columns=['sex', 'embarked'], drop_first=True)

# Resultado: sex_male (0/1), embarked_Q (0/1), embarked_S (0/1)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# LABEL ENCODING (variÃ¡veis ordinais)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Exemplo: size = ['Small', 'Medium', 'Large'] (tem ordem!)
size_map = {'Small': 1, 'Medium': 2, 'Large': 3}
df['size_encoded'] = df['size'].map(size_map)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# BINARY ENCODING (2 valores)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
df['sex_binary'] = df['sex'].map({'male': 0, 'female': 1})
# Ou:
df['sex_binary'] = (df['sex'] == 'female').astype(int)
```

---

### âš–ï¸ SeparaÃ§Ã£o Features e Target

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# MÃ‰TODO 1: Drop
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
X = df.drop('target', axis=1)       # Features (tudo exceto target)
y = df['target']                    # Target

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# MÃ‰TODO 2: Selecionar colunas
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
X = df[['age', 'fare', 'pclass', 'sex_male']]
y = df['survived']

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# TRAIN/TEST SPLIT
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,           # 20% para teste
    random_state=42,         # Reprodutibilidade
    stratify=y               # MantÃ©m proporÃ§Ã£o das classes
)

print(f"Train: {X_train.shape}, Test: {X_test.shape}")
```

---

### ğŸ“ NormalizaÃ§Ã£o (StandardScaler)

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# QUANDO USAR:
# - SVM (sensÃ­vel Ã  escala)
# - Neural Networks (sensÃ­vel Ã  escala)
# - K-Means, KNN (baseados em distÃ¢ncia)
#
# NÃƒO PRECISA:
# - Random Forest, Decision Tree (baseados em thresholds)
# - XGBoost, LightGBM (baseados em Ã¡rvores)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

scaler = StandardScaler()

# âš ï¸ REGRA DE OURO:
# fit_transform no TRAIN
# transform no TEST
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Transforma em DataFrame (opcional)
X_train_scaled = pd.DataFrame(
    X_train_scaled, 
    columns=X_train.columns,
    index=X_train.index
)
```

---

## ğŸ¤– PÃGINA 3: TREINAMENTO DE MODELOS

### ğŸŒ³ Decision Tree

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# CRIAR E TREINAR
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
dt_model = DecisionTreeClassifier(
    max_depth=5,              # Limita profundidade (evita overfitting)
    min_samples_split=20,     # MÃ­nimo de amostras para dividir
    random_state=42
)

dt_model.fit(X_train, y_train)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# PREVER E AVALIAR
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
y_pred = dt_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"AcurÃ¡cia: {accuracy:.2%}")
```

---

### ğŸŒ² Random Forest

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# CRIAR E TREINAR
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
rf_model = RandomForestClassifier(
    n_estimators=100,         # NÃºmero de Ã¡rvores
    max_depth=10,             # Profundidade mÃ¡xima
    min_samples_split=10,     # MÃ­nimo para dividir
    random_state=42,
    n_jobs=-1                 # Usa todos os cores
)

rf_model.fit(X_train, y_train)
y_pred = rf_model.predict(X_test)
y_proba = rf_model.predict_proba(X_test)[:, 1]  # Probabilidades

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# FEATURE IMPORTANCE
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
feature_imp = pd.DataFrame({
    'feature': X_train.columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print(feature_imp)
```

---

### âš¡ XGBoost

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# CRIAR E TREINAR
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
xgb_model = XGBClassifier(
    n_estimators=100,
    max_depth=5,
    learning_rate=0.1,        # Taxa de aprendizado
    random_state=42,
    eval_metric='logloss'     # MÃ©trica de avaliaÃ§Ã£o
)

xgb_model.fit(X_train, y_train)
y_pred = xgb_model.predict(X_test)
y_proba = xgb_model.predict_proba(X_test)[:, 1]
```

---

### ğŸ¯ SVM (Support Vector Machine)

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# âš ï¸ REQUER NORMALIZAÃ‡ÃƒO!
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
svm_model = SVC(
    kernel='rbf',             # 'linear', 'poly', 'rbf'
    C=1.0,                    # RegularizaÃ§Ã£o
    probability=True,         # Habilita predict_proba
    random_state=42
)

svm_model.fit(X_train_scaled, y_train)
y_pred = svm_model.predict(X_test_scaled)
y_proba = svm_model.predict_proba(X_test_scaled)[:, 1]
```

---

### ğŸ§  Neural Network (MLP)

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# âš ï¸ REQUER NORMALIZAÃ‡ÃƒO!
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
mlp_model = MLPClassifier(
    hidden_layer_sizes=(100, 50, 25),  # 3 camadas ocultas
    activation='relu',                  # 'relu', 'tanh', 'logistic'
    solver='adam',                      # 'adam', 'sgd', 'lbfgs'
    max_iter=500,                       # IteraÃ§Ãµes mÃ¡ximas
    random_state=42,
    early_stopping=True,                # Para quando nÃ£o melhora
    validation_fraction=0.1             # 10% para validaÃ§Ã£o
)

mlp_model.fit(X_train_scaled, y_train)
y_pred = mlp_model.predict(X_test_scaled)
y_proba = mlp_model.predict_proba(X_test_scaled)[:, 1]
```

---

## ğŸ“Š PÃGINA 4: AVALIAÃ‡ÃƒO E VISUALIZAÃ‡ÃƒO

### ğŸ“ˆ MÃ©tricas de ClassificaÃ§Ã£o

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# MÃ‰TRICAS BÃSICAS
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
from sklearn.metrics import *

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"Accuracy:  {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1-Score:  {f1:.4f}")

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# RELATÃ“RIO COMPLETO
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
print(classification_report(y_test, y_pred))

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# CROSS-VALIDATION
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
from sklearn.model_selection import cross_val_score

cv_scores = cross_val_score(model, X_train, y_train, cv=5)
print(f"CV Scores: {cv_scores}")
print(f"CV Mean: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
```

---

### ğŸ¨ Matriz de ConfusÃ£o

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# CALCULAR
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
cm = confusion_matrix(y_test, y_pred)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# VISUALIZAR
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Neg', 'Pos'],
            yticklabels=['Neg', 'Pos'])
plt.xlabel('Predito')
plt.ylabel('Real')
plt.title('Matriz de ConfusÃ£o')
plt.show()

# InterpretaÃ§Ã£o:
#           Predito
#        |  0  |  1  |
# Real 0 | TN  | FP  |  â† Verdadeiros Negativos | Falsos Positivos
#      1 | FN  | TP  |  â† Falsos Negativos | Verdadeiros Positivos
```

---

### ğŸ“‰ Curva ROC

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# CALCULAR ROC-AUC
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
from sklearn.metrics import roc_curve, roc_auc_score

# Probabilidades necessÃ¡rias!
y_proba = model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
auc = roc_auc_score(y_test, y_proba)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# PLOTAR
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC (AUC = {auc:.3f})', linewidth=2)
plt.plot([0, 1], [0, 1], 'k--', label='Random')  # Linha de referÃªncia
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curva ROC')
plt.legend()
plt.grid(alpha=0.3)
plt.show()
```

---

### ğŸ“Š Feature Importance (Random Forest/XGBoost)

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# EXTRAIR IMPORTÃ‚NCIAS
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
feature_imp = pd.DataFrame({
    'feature': X_train.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# PLOTAR (Top 10)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
plt.figure(figsize=(10, 6))
plt.barh(feature_imp['feature'][:10], 
         feature_imp['importance'][:10])
plt.xlabel('ImportÃ¢ncia')
plt.title('Top 10 Features Mais Importantes')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()
```

---

### ğŸ”„ ComparaÃ§Ã£o de MÃºltiplos Modelos

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# TREINAR VÃRIOS MODELOS
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
models = {
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss'),
    'SVM': SVC(random_state=42),
    'MLP': MLPClassifier(random_state=42, max_iter=500)
}

results = []

for name, model in models.items():
    # Treinar (usar scaled para SVM e MLP)
    if name in ['SVM', 'MLP']:
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
    
    # MÃ©tricas
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    
    results.append({
        'Model': name,
        'Accuracy': acc,
        'Precision': prec,
        'Recall': rec,
        'F1-Score': f1
    })

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# DATAFRAME DE RESULTADOS
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
results_df = pd.DataFrame(results)
results_df = results_df.sort_values('Accuracy', ascending=False)
print(results_df.to_string(index=False))

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# PLOTAR COMPARAÃ‡ÃƒO
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
results_df.set_index('Model')[['Accuracy', 'Precision', 
                                 'Recall', 'F1-Score']].plot(kind='bar', 
                                                              figsize=(12, 6))
plt.title('ComparaÃ§Ã£o de Modelos')
plt.ylabel('Score')
plt.xlabel('Modelo')
plt.xticks(rotation=45)
plt.legend(loc='lower right')
plt.ylim(0, 1)
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.show()
```

---

### ğŸ’¾ Salvar e Carregar Modelos

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# SALVAR
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
import joblib

joblib.dump(model, 'modelo_treinado.pkl')
joblib.dump(scaler, 'scaler.pkl')

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# CARREGAR
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
model_loaded = joblib.load('modelo_treinado.pkl')
scaler_loaded = joblib.load('scaler.pkl')

# Usar
X_new_scaled = scaler_loaded.transform(X_new)
predictions = model_loaded.predict(X_new_scaled)
```

---

## ğŸ¯ DICAS RÃPIDAS

### âœ… Checklist de Workflow ML

```
1. [ ] Carregar dados (read_csv)
2. [ ] EDA (describe, info, correlaÃ§Ã£o)
3. [ ] Tratar valores faltantes (fillna ou dropna)
4. [ ] Encoding de categÃ³ricas (get_dummies)
5. [ ] Separar X e y
6. [ ] Train/Test Split (80-20)
7. [ ] Normalizar SE necessÃ¡rio (StandardScaler)
8. [ ] Treinar modelo (fit)
9. [ ] Fazer previsÃµes (predict)
10. [ ] Avaliar (accuracy, confusion_matrix, etc.)
11. [ ] Comparar modelos
12. [ ] Salvar melhor modelo (joblib)
```

---

### âš ï¸ Erros Comuns para Evitar

```python
# âŒ ERRO 1: fit_transform no test
X_test_scaled = scaler.fit_transform(X_test)  # ERRADO!

# âœ… CERTO:
X_test_scaled = scaler.transform(X_test)


# âŒ ERRO 2: Usar dados scaled em modelos de Ã¡rvore
rf_model.fit(X_train_scaled, y_train)  # DesnecessÃ¡rio!

# âœ… CERTO:
rf_model.fit(X_train, y_train)  # Random Forest nÃ£o precisa


# âŒ ERRO 3: Esquecer random_state
model = RandomForestClassifier()  # Resultados variam!

# âœ… CERTO:
model = RandomForestClassifier(random_state=42)


# âŒ ERRO 4: Misturar train e test
model.fit(X, y)  # Treinou com tudo!
score = model.score(X, y)  # Testou com tudo = enviesado

# âœ… CERTO:
model.fit(X_train, y_train)
score = model.score(X_test, y_test)
```

---

### ğŸ“š Quando Usar Cada Modelo

| Modelo | Quando Usar | Vantagens | Desvantagens |
|--------|-------------|-----------|--------------|
| **Decision Tree** | Baseline rÃ¡pido | InterpretÃ¡vel, rÃ¡pido | Overfit fÃ¡cil |
| **Random Forest** | Dados tabulares gerais | Robusto, boa acurÃ¡cia | Lento, menos interpretÃ¡vel |
| **XGBoost** | CompetiÃ§Ãµes, mÃ¡xima performance | Melhor acurÃ¡cia, rÃ¡pido | Complexo, muitos hiperparÃ¢metros |
| **SVM** | Dados com boa separaÃ§Ã£o | Eficaz em alta dimensÃ£o | Lento, requer normalizaÃ§Ã£o |
| **MLP** | PadrÃµes complexos | Aprende relaÃ§Ãµes nÃ£o-lineares | Caixa-preta, requer normalizaÃ§Ã£o |

---

### ğŸ¨ ConfiguraÃ§Ã£o de Plots (Opcional)

```python
# Configurar estilo global
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Aumentar tamanho padrÃ£o de fontes
plt.rcParams['font.size'] = 12
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['axes.titlesize'] = 16
plt.rcParams['figure.figsize'] = (10, 6)
```

---

**ğŸ“„ FIM DO CHEATSHEET | Salve e imprima para consulta rÃ¡pida! ğŸš€**

_Criado para: Aprendizado IA 2025 - Semana 3_
