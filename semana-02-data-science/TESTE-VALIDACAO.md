# ğŸ§ª Teste de ValidaÃ§Ã£o - Semana 2: Data Science e EDA

## â±ï¸ Tempo estimado: 20 minutos

---

## ğŸ“‹ Parte 1: Conceitos (mÃºltipla escolha)

### QuestÃ£o 1: AnÃ¡lise ExploratÃ³ria de Dados (EDA)
Por que fazer EDA antes de treinar modelos?

**A)** Para deixar o cÃ³digo mais bonito  
**B)** Para identificar padrÃµes, problemas e features importantes  
**C)** Porque Ã© obrigatÃ³rio no Scikit-learn  
**D)** Para fazer o modelo treinar mais rÃ¡pido  

<details>
<summary>ğŸ’¡ Ver resposta</summary>

**Resposta: B) Para identificar padrÃµes, problemas e features importantes**

**Por quÃª EDA Ã© crucial:**

### ğŸ” Objetivos da EDA:

1. **Identificar Problemas:**
```python
# Valores faltantes
df.isnull().sum()

# Outliers
df.describe()

# Tipos de dados incorretos
df.dtypes
```

2. **Descobrir PadrÃµes:**
```python
# CorrelaÃ§Ãµes
df.corr()

# DistribuiÃ§Ãµes
df['age'].hist()

# RelaÃ§Ãµes entre variÃ¡veis
sns.scatterplot(x='age', y='fare', data=df)
```

3. **Selecionar Features:**
```python
# Quais features sÃ£o mais informativas?
correlation_matrix = df.corr()
correlation_matrix['survived'].sort_values(ascending=False)
```

---

### ğŸ“Š Exemplo Real: Titanic

**Sem EDA:**
```python
# Treinar direto com todos os dados
model.fit(X, y)  # âŒ Pode ter problemas!
```

**Com EDA:**
```python
# Descobertas importantes:
âœ… Age tem 177 valores faltantes â†’ preencher
âœ… Cabin tem 687 valores faltantes â†’ remover ou criar feature
âœ… Sex correlaciona fortemente com sobrevivÃªncia â†’ manter!
âœ… Pclass correlaciona com sobrevivÃªncia â†’ manter!
âœ… Fare tem outliers extremos â†’ normalizar
```

---

### ğŸ¯ Checklist EDA BÃ¡sico:

- [ ] `.info()` - Tipos de dados e valores nulos
- [ ] `.describe()` - EstatÃ­sticas numÃ©ricas
- [ ] `.isnull().sum()` - Quantos valores faltantes
- [ ] `.corr()` - CorrelaÃ§Ãµes entre variÃ¡veis
- [ ] VisualizaÃ§Ãµes (histogramas, boxplots, scatter)

**Conceito-chave:** EDA evita surpresas ruins depois do treino!

</details>

---

### QuestÃ£o 2: CorrelaÃ§Ã£o
VocÃª tem este heatmap de correlaÃ§Ã£o:

```
          survived  age   fare  pclass
survived   1.00    -0.08  0.26  -0.34
age       -0.08     1.00  0.09  -0.37
fare       0.26     0.09  1.00  -0.55
pclass    -0.34    -0.37 -0.55   1.00
```

Qual feature tem **correlaÃ§Ã£o negativa mais forte** com `survived`?

**A)** age  
**B)** fare  
**C)** pclass  
**D)** Todas tÃªm correlaÃ§Ã£o positiva  

<details>
<summary>ğŸ’¡ Ver resposta</summary>

**Resposta: C) pclass (correlaÃ§Ã£o: -0.34)**

### ğŸ“Š AnÃ¡lise das CorrelaÃ§Ãµes:

#### 1ï¸âƒ£ **pclass â†’ survived: -0.34**
```
CorrelaÃ§Ã£o NEGATIVA MODERADA
```
**InterpretaÃ§Ã£o:**
- Quanto **maior** a classe (3Âª classe), **menor** a chance de sobreviver
- Ou: Quanto **menor** a classe (1Âª classe), **maior** a chance

**Por quÃª?**
- Passageiros de 1Âª classe (pclass=1): acesso a botes salva-vidas
- Passageiros de 3Âª classe (pclass=3): mais distantes dos botes

```python
# Verificar na prÃ¡tica:
df.groupby('pclass')['survived'].mean()
# 1Âª classe: 63% sobreviveram
# 2Âª classe: 47% sobreviveram
# 3Âª classe: 24% sobreviveram â† Confirmado!
```

---

#### 2ï¸âƒ£ **fare â†’ survived: +0.26**
```
CorrelaÃ§Ã£o POSITIVA FRACA/MODERADA
```
**InterpretaÃ§Ã£o:**
- Quanto **maior** a tarifa, **maior** a chance de sobreviver
- Tarifas altas = classes melhores = mais seguranÃ§a

---

#### 3ï¸âƒ£ **age â†’ survived: -0.08**
```
CorrelaÃ§Ã£o NEGATIVA MUITO FRACA (quase zero!)
```
**InterpretaÃ§Ã£o:**
- Idade quase **nÃ£o influencia** sobrevivÃªncia (surpresa!)
- Embora tenhamos "mulheres e crianÃ§as primeiro", a correlaÃ§Ã£o Ã© fraca

**Por quÃª?**
- Efeito neutralizado por outros fatores (classe, sexo)
- CrianÃ§as de 1Âª classe sobreviveram, mas de 3Âª nÃ£o

---

### ğŸ“ Escala de CorrelaÃ§Ã£o:

```
Valor         InterpretaÃ§Ã£o
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
+1.00         CorrelaÃ§Ã£o positiva perfeita
+0.70 a +1.00 CorrelaÃ§Ã£o positiva forte
+0.30 a +0.70 CorrelaÃ§Ã£o positiva moderada
+0.00 a +0.30 CorrelaÃ§Ã£o positiva fraca
 0.00         Sem correlaÃ§Ã£o
-0.00 a -0.30 CorrelaÃ§Ã£o negativa fraca
-0.30 a -0.70 CorrelaÃ§Ã£o negativa moderada  â† pclass estÃ¡ aqui!
-0.70 a -1.00 CorrelaÃ§Ã£o negativa forte
-1.00         CorrelaÃ§Ã£o negativa perfeita
```

---

### ğŸ¨ VisualizaÃ§Ã£o Ãštil:

```python
import seaborn as sns
import matplotlib.pyplot as plt

# Heatmap de correlaÃ§Ã£o
plt.figure(figsize=(8, 6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', center=0)
plt.title('CorrelaÃ§Ã£o entre VariÃ¡veis')
plt.show()

# Cores:
# Vermelho = correlaÃ§Ã£o positiva
# Azul = correlaÃ§Ã£o negativa
# Branco = sem correlaÃ§Ã£o
```

---

### âš ï¸ Cuidados com CorrelaÃ§Ã£o:

**1. CorrelaÃ§Ã£o â‰  Causalidade**
```
Exemplo:
Vendas de sorvete â†” Afogamentos (correlaÃ§Ã£o +0.8)
Mas sorvete NÃƒO causa afogamento!
Ambos aumentam no verÃ£o (variÃ¡vel oculta)
```

**2. Apenas VariÃ¡veis NumÃ©ricas**
```python
# âŒ CorrelaÃ§Ã£o com categÃ³ricas nÃ£o faz sentido
df[['survived', 'sex']].corr()  # sex Ã© texto!

# âœ… Converter para numÃ©rico primeiro
df['sex_encoded'] = df['sex'].map({'male': 0, 'female': 1})
df[['survived', 'sex_encoded']].corr()  # Agora sim!
```

**Conceito-chave:** CorrelaÃ§Ã£o mostra ASSOCIAÃ‡ÃƒO, nÃ£o causa e efeito!

</details>

---

### QuestÃ£o 3: Encoding de VariÃ¡veis CategÃ³ricas
VocÃª tem uma coluna `embarked` com valores: S, C, Q

Qual o mÃ©todo correto para usar no modelo?

**A)** Usar diretamente: `X = df[['embarked']]`  
**B)** One-Hot Encoding: `pd.get_dummies(df['embarked'])`  
**C)** Converter para nÃºmeros: `{'S': 1, 'C': 2, 'Q': 3}`  
**D)** Remover a coluna  

<details>
<summary>ğŸ’¡ Ver resposta</summary>

**Resposta: B) One-Hot Encoding: `pd.get_dummies(df['embarked'])`**

### ğŸ¯ Por quÃª?

#### âŒ OpÃ§Ã£o A: Usar texto diretamente
```python
X = df[['embarked']]  # ['S', 'C', 'Q', ...]

model.fit(X, y)  # âŒ ERRO!
# ValueError: could not convert string to float
```
**Problema:** Modelos ML sÃ³ entendem nÃºmeros!

---

#### âŒ OpÃ§Ã£o C: Label Encoding (1, 2, 3)
```python
embarked_map = {'S': 1, 'C': 2, 'Q': 3}
df['embarked_encoded'] = df['embarked'].map(embarked_map)
```

**Problema:** Cria **ordem artificial**!
```
S=1 < C=2 < Q=3
Modelo pensa: Q Ã© "maior" que S
Mas nÃ£o hÃ¡ ordem! SÃ£o apenas portos diferentes!
```

**Quando usar Label Encoding:**
- VariÃ¡veis **ordinais** (tem ordem natural)
- Exemplos: `tamanho = ['P', 'M', 'G']`, `nota = ['Ruim', 'Bom', 'Ã“timo']`

---

#### âœ… OpÃ§Ã£o B: One-Hot Encoding
```python
# Antes:
embarked
---------
S
C
S
Q

# Depois:
embarked_S  embarked_C  embarked_Q
1           0           0
0           1           0
1           0           0
0           0           1
```

**Vantagens:**
- âœ… Sem ordem artificial
- âœ… Cada categoria vira coluna binÃ¡ria (0/1)
- âœ… Modelo trata cada categoria independentemente

**CÃ³digo:**
```python
# MÃ©todo 1: Pandas
df_encoded = pd.get_dummies(df, columns=['embarked'], drop_first=False)

# MÃ©todo 2: Scikit-learn
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(sparse_output=False)
embarked_encoded = encoder.fit_transform(df[['embarked']])
```

---

### ğŸ“ Quando Usar Cada MÃ©todo:

| Tipo de VariÃ¡vel | MÃ©todo | Exemplo |
|------------------|--------|---------|
| **Nominal** (sem ordem) | One-Hot Encoding | Cor, Porto, PaÃ­s |
| **Ordinal** (com ordem) | Label Encoding | Tamanho (P/M/G), Nota (1-5) |
| **BinÃ¡ria** (2 valores) | 0/1 ou One-Hot | Sim/NÃ£o, Masculino/Feminino |

---

### âš ï¸ Problema: Dummy Variable Trap

```python
# âŒ Com drop_first=False (padrÃ£o):
embarked_S  embarked_C  embarked_Q
1           0           0
0           1           0
0           0           1

# RedundÃ¢ncia: Se S=0 e C=0, entÃ£o Q=1 (sempre!)
# Causa multicolinearidade

# âœ… Com drop_first=True:
embarked_C  embarked_Q
0           0          # S estÃ¡ "implÃ­cito" (ambas sÃ£o 0)
1           0          # C
0           1          # Q
```

**Regra:**
```python
pd.get_dummies(df, columns=['embarked'], drop_first=True)
# Cria n-1 colunas (n = nÃºmero de categorias)
```

---

### ğŸ’» Exemplo Completo:

```python
import pandas as pd

# Dataset original
df = pd.DataFrame({
    'name': ['John', 'Anna', 'Peter'],
    'embarked': ['S', 'C', 'S'],
    'age': [22, 38, 25]
})

# Aplicar One-Hot Encoding
df_encoded = pd.get_dummies(df, columns=['embarked'], drop_first=True)

print(df_encoded)
#    name  age  embarked_C  embarked_Q  embarked_S
# 0  John   22           0           0           1
# 1  Anna   38           1           0           0
# 2  Peter  25           0           0           1

# Usar no modelo
X = df_encoded[['age', 'embarked_C', 'embarked_Q', 'embarked_S']]
y = df['survived']

model.fit(X, y)  # âœ… Funciona!
```

**Conceito-chave:** CategÃ³ricas nominais â†’ One-Hot Encoding!

</details>

---

### QuestÃ£o 4: Valores Faltantes (Missing Values)
VocÃª tem uma coluna `age` com 20% de valores NaN. O que fazer?

**A)** Remover todas as linhas com NaN  
**B)** Preencher com a mÃ©dia ou mediana  
**C)** Deixar NaN (o modelo aceita)  
**D)** Remover a coluna `age`  

<details>
<summary>ğŸ’¡ Ver resposta</summary>

**Resposta: B) Preencher com a mÃ©dia ou mediana**

### ğŸ¯ Por quÃª?

#### âŒ OpÃ§Ã£o A: Remover linhas
```python
df_clean = df.dropna(subset=['age'])
```

**Problemas:**
- âŒ Perde 20% dos dados (177 linhas no Titanic!)
- âŒ Reduz poder estatÃ­stico
- âŒ Pode introduzir viÃ©s (se NaNs nÃ£o sÃ£o aleatÃ³rios)

**Quando usar:**
- <5% de valores faltantes
- Muitos dados disponÃ­veis (milhÃµes de linhas)

---

#### âŒ OpÃ§Ã£o C: Deixar NaN
```python
model.fit(X, y)  # âŒ ValueError: Input contains NaN
```

**Problema:** A maioria dos modelos nÃ£o aceita NaN!

**ExceÃ§Ãµes:**
- XGBoost e LightGBM (lidam nativamente com NaN)
- Alguns modelos do scikit-learn com `SimpleImputer`

---

#### âŒ OpÃ§Ã£o D: Remover coluna
```python
df.drop('age', axis=1)
```

**Problemas:**
- âŒ Perde informaÃ§Ã£o potencialmente Ãºtil
- âŒ Age pode ser importante para previsÃ£o

**Quando usar:**
- >70% de valores faltantes
- Feature demonstra nÃ£o ser importante (correlaÃ§Ã£o ~0)

---

#### âœ… OpÃ§Ã£o B: ImputaÃ§Ã£o (Preencher)

### 1. **MÃ©dia vs Mediana**

```python
# MÃ©dia (se distribuiÃ§Ã£o normal)
df['age'].fillna(df['age'].mean(), inplace=True)

# Mediana (se tem outliers)
df['age'].fillna(df['age'].median(), inplace=True)
```

**Quando usar cada uma:**
```
DistribuiÃ§Ã£o Normal â†’ MÃ©dia
DistribuiÃ§Ã£o AssimÃ©trica â†’ Mediana
Outliers presentes â†’ Mediana
```

---

### 2. **MÃ©todos AvanÃ§ados**

#### a) **Preencher por Grupo**
```python
# Preencher age baseado na mÃ©dia por sexo
df['age'] = df.groupby('sex')['age'].transform(
    lambda x: x.fillna(x.median())
)

# LÃ³gica: Homens e mulheres podem ter idades mÃ©dias diferentes
```

#### b) **Forward Fill / Backward Fill**
```python
# Para sÃ©ries temporais
df['age'].fillna(method='ffill')  # Usa valor anterior
df['age'].fillna(method='bfill')  # Usa prÃ³ximo valor
```

#### c) **InterpolaÃ§Ã£o**
```python
df['age'].interpolate(method='linear')
# Estima baseado em valores vizinhos
```

#### d) **Criar Feature Indicadora**
```python
# Adicionar coluna "age_was_missing"
df['age_missing'] = df['age'].isnull().astype(int)
df['age'].fillna(df['age'].median(), inplace=True)

# Permite ao modelo saber quando age foi imputado
```

---

### 3. **Scikit-learn SimpleImputer**

```python
from sklearn.impute import SimpleImputer

# EstratÃ©gias: 'mean', 'median', 'most_frequent', 'constant'
imputer = SimpleImputer(strategy='median')

df[['age']] = imputer.fit_transform(df[['age']])
```

---

### ğŸ“Š Exemplo Completo:

```python
import pandas as pd
import numpy as np

# Dataset com NaNs
df = pd.DataFrame({
    'age': [25, np.nan, 30, np.nan, 40],
    'sex': ['M', 'F', 'M', 'F', 'M']
})

print("Antes:")
print(df)
#    age sex
# 0  25.0   M
# 1   NaN   F
# 2  30.0   M
# 3   NaN   F
# 4  40.0   M

# Preencher com mediana por sexo
df['age'] = df.groupby('sex')['age'].transform(
    lambda x: x.fillna(x.median())
)

print("\nDepois:")
print(df)
#    age sex
# 0  25.0   M
# 1  30.0   F  â† Preenchido com mediana de F (se houver)
# 2  30.0   M
# 3  30.0   F
# 4  40.0   M
```

---

### ğŸ¯ Checklist de DecisÃ£o:

```
Valores Faltantes
    â†“
< 5% dos dados?
    â”œâ”€ Sim â†’ Remover linhas (dropna)
    â””â”€ NÃ£o â†’ Continuar
        â†“
    Feature importante?
        â”œâ”€ NÃ£o â†’ Remover coluna
        â””â”€ Sim â†’ Imputar
            â†“
        DistribuiÃ§Ã£o normal?
            â”œâ”€ Sim â†’ MÃ©dia
            â””â”€ NÃ£o â†’ Mediana
```

**Conceito-chave:** Escolha o mÃ©todo baseado nos dados e no problema!

</details>

---

## ğŸ–¥ï¸ Parte 2: PrÃ¡tica (cÃ³digo)

### Desafio: Pipeline Completo de EDA

Complete o cÃ³digo abaixo:

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Carregar dados
df = pd.read_csv('titanic.csv')

# 1ï¸âƒ£ PREENCHA: InformaÃ§Ãµes bÃ¡sicas do dataset
print("Shape:", __________)
print("\nTipos de dados:")
print(__________)
print("\nValores faltantes:")
print(__________)

# 2ï¸âƒ£ PREENCHA: EstatÃ­sticas descritivas
print("\nEstatÃ­sticas:")
print(__________)

# 3ï¸âƒ£ PREENCHA: Preencher valores faltantes de 'age' com mediana
df['age'].fillna(__________, inplace=True)

# 4ï¸âƒ£ PREENCHA: Criar encoding para 'sex'
df['sex_encoded'] = df['sex'].map(__________)

# 5ï¸âƒ£ PREENCHA: Calcular correlaÃ§Ã£o com target
correlation = __________
print("\nCorrelaÃ§Ã£o com survived:")
print(correlation['survived'].sort_values(ascending=False))

# 6ï¸âƒ£ Visualizar (jÃ¡ preenchido)
plt.figure(figsize=(8, 6))
sns.heatmap(correlation, annot=True, cmap='coolwarm')
plt.title('Heatmap de CorrelaÃ§Ã£o')
plt.show()
```

<details>
<summary>ğŸ’¡ Ver resposta completa</summary>

### âœ… CÃ³digo Completo:

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Carregar dados
df = pd.read_csv('titanic.csv')

# 1ï¸âƒ£ InformaÃ§Ãµes bÃ¡sicas do dataset
print("Shape:", df.shape)
print("\nTipos de dados:")
print(df.dtypes)
print("\nValores faltantes:")
print(df.isnull().sum())

# 2ï¸âƒ£ EstatÃ­sticas descritivas
print("\nEstatÃ­sticas:")
print(df.describe())

# 3ï¸âƒ£ Preencher valores faltantes de 'age' com mediana
df['age'].fillna(df['age'].median(), inplace=True)

# 4ï¸âƒ£ Criar encoding para 'sex'
df['sex_encoded'] = df['sex'].map({'male': 0, 'female': 1})

# 5ï¸âƒ£ Calcular correlaÃ§Ã£o com target
# Selecionar apenas colunas numÃ©ricas
correlation = df[['survived', 'pclass', 'age', 'sibsp', 
                  'parch', 'fare', 'sex_encoded']].corr()
print("\nCorrelaÃ§Ã£o com survived:")
print(correlation['survived'].sort_values(ascending=False))

# 6ï¸âƒ£ Visualizar
plt.figure(figsize=(8, 6))
sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0)
plt.title('Heatmap de CorrelaÃ§Ã£o')
plt.tight_layout()
plt.show()
```

---

### ğŸ“ ExplicaÃ§Ã£o Linha por Linha:

#### 1ï¸âƒ£ InformaÃ§Ãµes BÃ¡sicas
```python
df.shape         # (891, 12) = 891 linhas, 12 colunas
df.dtypes        # int64, float64, object (string)
df.isnull().sum() # Quantidade de NaNs por coluna
```

**Output esperado:**
```
Shape: (891, 12)

Tipos de dados:
survived      int64
pclass        int64
name         object  â† String
sex          object  â† String
age         float64
...

Valores faltantes:
survived      0
pclass        0
name          0
sex           0
age         177  â† Tem NaNs!
cabin       687  â† Muitos NaNs!
embarked      2
...
```

---

#### 2ï¸âƒ£ EstatÃ­sticas
```python
df.describe()
```

**Mostra:** count, mean, std, min, 25%, 50%, 75%, max

**Ãštil para:**
- Identificar outliers (max muito diferente do 75%)
- Ver distribuiÃ§Ã£o (mean vs 50%)
- Detectar valores impossÃ­veis (idade negativa)

---

#### 3ï¸âƒ£ ImputaÃ§Ã£o
```python
df['age'].fillna(df['age'].median(), inplace=True)
```

**Alternativas:**
```python
# MÃ©dia
df['age'].fillna(df['age'].mean(), inplace=True)

# Valor constante
df['age'].fillna(0, inplace=True)

# Por grupo
df['age'] = df.groupby('pclass')['age'].transform(
    lambda x: x.fillna(x.median())
)
```

---

#### 4ï¸âƒ£ Encoding
```python
df['sex_encoded'] = df['sex'].map({'male': 0, 'female': 1})
```

**Resultado:**
```
sex       sex_encoded
male      0
female    1
male      0
female    1
```

**Alternativa (One-Hot):**
```python
df = pd.get_dummies(df, columns=['sex'], drop_first=True)
# Cria: sex_male (0/1)
```

---

#### 5ï¸âƒ£ CorrelaÃ§Ã£o
```python
# Selecionar apenas numÃ©ricas
correlation = df[['survived', 'pclass', 'age', 'sibsp', 
                  'parch', 'fare', 'sex_encoded']].corr()

# Ver correlaÃ§Ã£o com target
correlation['survived'].sort_values(ascending=False)
```

**Output esperado:**
```
survived        1.00   â† Sempre 1 (consigo mesmo)
sex_encoded     0.54   â† Forte correlaÃ§Ã£o positiva!
fare            0.26
parch           0.08
age            -0.08
sibsp          -0.04
pclass         -0.34   â† CorrelaÃ§Ã£o negativa moderada
```

**InterpretaÃ§Ã£o:**
- `sex_encoded` (female=1) tem correlaÃ§Ã£o +0.54 â†’ Mulheres sobreviveram mais!
- `pclass` tem correlaÃ§Ã£o -0.34 â†’ Classe baixa sobreviveu menos

---

### ğŸ“Š VisualizaÃ§Ãµes Adicionais Ãšteis:

```python
# DistribuiÃ§Ã£o de idade
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
df['age'].hist(bins=30, edgecolor='black')
plt.title('DistribuiÃ§Ã£o de Idade')

# SobrevivÃªncia por sexo
plt.subplot(1, 2, 2)
df.groupby('sex')['survived'].mean().plot(kind='bar')
plt.title('Taxa de SobrevivÃªncia por Sexo')
plt.ylabel('Taxa')
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

# Pairplot (relaÃ§Ãµes entre variÃ¡veis)
sns.pairplot(df[['survived', 'age', 'fare', 'pclass']], hue='survived')
plt.show()
```

**Conceito-chave:** EDA Ã© exploraÃ§Ã£o visual + numÃ©rica!

</details>

---

## ğŸ“Š Parte 3: InterpretaÃ§Ã£o de VisualizaÃ§Ã£o

VocÃª criou este grÃ¡fico:

```python
df.groupby('pclass')['survived'].mean().plot(kind='bar')
```

Resultado:
```
1Âª classe: 0.63 (63%)
2Âª classe: 0.47 (47%)
3Âª classe: 0.24 (24%)
```

### QuestÃ£o: O que vocÃª pode concluir e como isso afeta seu modelo?

<details>
<summary>ğŸ’¡ Ver resposta e anÃ¡lise</summary>

### ğŸ“Š ConclusÃµes e ImplicaÃ§Ãµes:

#### 1ï¸âƒ£ **ConclusÃ£o Principal:**
```
Classe social influencia FORTEMENTE a sobrevivÃªncia!
1Âª classe: 2.6x mais chance que 3Âª classe
```

**Por quÃª isso aconteceu:**
- 1Âª classe: Quartos prÃ³ximos aos botes salva-vidas
- 3Âª classe: Quartos no fundo do navio, mais longe
- Prioridade no resgate para passageiros de 1Âª classe

---

#### 2ï¸âƒ£ **ImplicaÃ§Ãµes para o Modelo:**

**a) Feature Importance**
```python
# pclass Ã© uma feature MUITO IMPORTANTE!
# NÃƒO remover essa coluna

âœ… Incluir pclass no modelo
âœ… Considerar criar features derivadas
```

**b) Features Derivadas**
```python
# Exemplo: criar feature "is_first_class"
df['is_first_class'] = (df['pclass'] == 1).astype(int)

# Exemplo: agrupar classes
df['high_class'] = (df['pclass'] <= 2).astype(int)
```

**c) InteraÃ§Ãµes entre Features**
```python
# pclass pode interagir com outras features
# Exemplo: Mulheres de 1Âª classe sobreviveram MUITO mais

# Criar feature de interaÃ§Ã£o
df['female_first_class'] = (
    (df['sex'] == 'female') & (df['pclass'] == 1)
).astype(int)
```

---

#### 3ï¸âƒ£ **AnÃ¡lise Mais Profunda:**

```python
# SobrevivÃªncia por classe E sexo
survival_by_class_sex = df.groupby(['pclass', 'sex'])['survived'].mean()

print(survival_by_class_sex)
```

**Resultado esperado:**
```
pclass  sex
1       female    0.97  â† 97%! Quase todas sobreviveram
        male      0.37
2       female    0.92
        male      0.16
3       female    0.50
        male      0.14  â† Apenas 14%
```

**Insights:**
- Mulheres de 1Âª e 2Âª classe: >90% sobreviveram
- Homens de 2Âª e 3Âª classe: <20% sobreviveram
- Sexo + Classe combinados explicam MUITO da sobrevivÃªncia

---

#### 4ï¸âƒ£ **EstratÃ©gias de Modelagem:**

**a) Feature Engineering**
```python
# Criar combinaÃ§Ãµes de features
df['sex_class'] = df['sex'] + '_' + df['pclass'].astype(str)
# Valores: 'female_1', 'male_1', 'female_2', etc.

# One-Hot Encoding
df = pd.get_dummies(df, columns=['sex_class'])
```

**b) Modelos Baseados em Ãrvore**
```python
# Random Forest, XGBoost, Decision Tree
# Naturalmente capturam interaÃ§Ãµes entre features

model = RandomForestClassifier()
model.fit(X_train, y_train)

# Verificar importÃ¢ncia
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

# Esperado: pclass e sex no topo!
```

**c) Balanceamento de Classes**
```python
# Se dataset estiver desbalanceado
from sklearn.utils import resample

# Oversample da classe minoritÃ¡ria
# Ou usar class_weight='balanced' no modelo
```

---

#### 5ï¸âƒ£ **ComunicaÃ§Ã£o de Resultados:**

**Para Stakeholders:**
```markdown
# Principais Achados:

1. **Classe social Ã© fator crÃ­tico:**
   - Passageiros de 1Âª classe: 63% sobreviveram
   - Passageiros de 3Âª classe: 24% sobreviveram

2. **CombinaÃ§Ã£o de fatores:**
   - Mulheres de 1Âª classe: 97% de sobrevivÃªncia
   - Homens de 3Âª classe: 14% de sobrevivÃªncia

3. **RecomendaÃ§Ãµes para o modelo:**
   - Incluir `pclass` como feature principal
   - Considerar interaÃ§Ãµes com `sex`
   - Explorar features derivadas da classe
```

---

### ğŸ“Š VisualizaÃ§Ã£o Completa:

```python
import matplotlib.pyplot as plt
import seaborn as sns

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# GrÃ¡fico 1: SobrevivÃªncia por classe
survival_by_class = df.groupby('pclass')['survived'].mean()
axes[0].bar([1, 2, 3], survival_by_class, 
            color=['gold', 'silver', 'brown'], edgecolor='black')
axes[0].set_xlabel('Classe')
axes[0].set_ylabel('Taxa de SobrevivÃªncia')
axes[0].set_title('SobrevivÃªncia por Classe Social')
axes[0].set_ylim(0, 1)
axes[0].axhline(y=0.5, color='r', linestyle='--', alpha=0.5)

# GrÃ¡fico 2: SobrevivÃªncia por classe e sexo
survival_matrix = df.groupby(['pclass', 'sex'])['survived'].mean().unstack()
survival_matrix.plot(kind='bar', ax=axes[1], color=['#e74c3c', '#2ecc71'])
axes[1].set_xlabel('Classe')
axes[1].set_ylabel('Taxa de SobrevivÃªncia')
axes[1].set_title('SobrevivÃªncia por Classe e Sexo')
axes[1].set_xticklabels(['1Âª', '2Âª', '3Âª'], rotation=0)
axes[1].legend(['Masculino', 'Feminino'])
axes[1].axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)

plt.tight_layout()
plt.show()
```

---

**Conceito-chave:** VisualizaÃ§Ãµes revelam insights que direcionam feature engineering!

</details>

---

## ğŸ“ Gabarito de Auto-AvaliaÃ§Ã£o

### PontuaÃ§Ã£o:

- **Parte 1 (Conceitos):** 4 questÃµes Ã— 2.5 pontos = **10 pontos**
- **Parte 2 (CÃ³digo):** 1 exercÃ­cio Ã— 5 pontos = **5 pontos**  
- **Parte 3 (InterpretaÃ§Ã£o):** 1 questÃ£o Ã— 5 pontos = **5 pontos**

**TOTAL:** 20 pontos

---

### ğŸ“Š InterpretaÃ§Ã£o da sua nota:

#### ğŸ† 17-20 pontos: EXCELENTE!
**VocÃª dominou EDA e Data Science bÃ¡sico!**

âœ… Entende o propÃ³sito da EDA  
âœ… Sabe interpretar correlaÃ§Ãµes  
âœ… Domina encoding e tratamento de dados  
âœ… Consegue extrair insights de visualizaÃ§Ãµes  

**PrÃ³ximos passos:**
- âœ… AVANÃ‡AR para Semana 3 com confianÃ§a!
- Continue praticando EDA em outros datasets

---

#### ğŸ’ª 13-16 pontos: BOM!
**VocÃª entende os conceitos principais, reforce alguns pontos.**

âœ… EDA bÃ¡sico estÃ¡ claro  
âš ï¸ Alguns detalhes precisam de atenÃ§Ã£o  

**PrÃ³ximos passos:**
- Revise as questÃµes que errou
- Pratique mais visualizaÃ§Ãµes
- Pode avanÃ§ar para Semana 3, mas consulte material S2

---

#### ğŸ”„ 9-12 pontos: PARCIAL
**Recomendado revisar antes de avanÃ§ar.**

âš ï¸ Conceitos de EDA nÃ£o estÃ£o totalmente claros  
âš ï¸ Pode ter dificuldade na Semana 3  

**PrÃ³ximos passos:**
- RefaÃ§a o notebook de EDA da Semana 2
- Foque em correlaÃ§Ã£o e encoding
- Pratique interpretaÃ§Ã£o de grÃ¡ficos
- RefaÃ§a o teste apÃ³s 2-3 dias

---

#### ğŸ“š 0-8 pontos: REVISAR
**EDA Ã© crucial para ML. Vale a pena reforÃ§ar!**

âŒ Fundamentos de anÃ¡lise de dados precisam de atenÃ§Ã£o  

**PrÃ³ximos passos:**
1. Releia a documentaÃ§Ã£o da Semana 2
2. Execute cada visualizaÃ§Ã£o com atenÃ§Ã£o
3. Pratique com outros datasets (Kaggle)
4. Anote os insights de cada grÃ¡fico
5. Retome este teste em 1 semana

---

## ğŸ¯ ReflexÃ£o Final

Responda honestamente (sÃ³ para vocÃª):

1. **Sei fazer EDA bÃ¡sico (correlaÃ§Ã£o, visualizaÃ§Ãµes)?**  
   [ ] Sim [ ] Mais ou menos [ ] Preciso revisar  

2. **Entendo quando usar One-Hot vs Label Encoding?**  
   [ ] Sim [ ] Mais ou menos [ ] Preciso revisar  

3. **Consigo tratar valores faltantes adequadamente?**  
   [ ] Sim [ ] Mais ou menos [ ] Preciso revisar  

4. **Me sinto confortÃ¡vel interpretando grÃ¡ficos e correlaÃ§Ãµes?**  
   [ ] Sim [ ] Com ajuda [ ] Ainda nÃ£o  

---

## âœ… DecisÃ£o Final

### â¡ï¸ AVANCE para Semana 3 se:
- Acertou 13+ pontos
- Respondeu "Sim" ou "Mais ou menos" na maioria das reflexÃµes
- Sente que consegue fazer EDA em novos datasets

### ğŸ”„ REVISE Semana 2 se:
- Acertou <9 pontos
- Respondeu "Preciso revisar" em 3+ reflexÃµes
- VisualizaÃ§Ãµes e correlaÃ§Ãµes ainda confusas

---

## ğŸ’¡ Dica Final

**EDA Ã© 50% do trabalho em Data Science!**

```
Data Science = 50% EDA + 30% Feature Engineering + 20% Modelagem
```

**Tempo bem investido em EDA:**
- âœ… Evita erros bobos (dados faltantes)
- âœ… Revela features importantes
- âœ… Sugere feature engineering
- âœ… Melhora performance do modelo

**"Se vocÃª tortura os dados por tempo suficiente, eles confessam tudo!"** ğŸ“Š

---

**Sucesso! EDA Ã© uma habilidade que vocÃª usarÃ¡ SEMPRE! ğŸ¯**

_Este teste pode ser refeito sempre que quiser. Pratique com novos datasets!_
