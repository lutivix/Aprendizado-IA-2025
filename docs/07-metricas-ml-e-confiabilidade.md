# ğŸ“Š MÃ©tricas de ML e Confiabilidade de Modelos

**Data:** 28 Outubro 2025  
**Contexto:** Semana 2 - Dia 1 (AnÃ¡lise do modelo Titanic)

---

## ğŸ¯ **As 4 MÃ©tricas Essenciais**

### **VisÃ£o Geral:**

| MÃ©trica | Pergunta que Responde | FÃ³rmula | Quando Usar |
|---------|----------------------|---------|-------------|
| **Accuracy** | Quantos % acertei no total? | (TP+TN) / Total | Dados balanceados |
| **Precision** | Quando digo SIM, acerto quantos %? | TP / (TP+FP) | Custo FP alto |
| **Recall** | De todos os SIM reais, pego quantos %? | TP / (TP+FN) | Custo FN alto |
| **F1-Score** | Qual equilÃ­brio entre Precision e Recall? | 2Ã—(PÃ—R)/(P+R) | Comparar modelos |

---

## ğŸ“ **Matriz de ConfusÃ£o**

```
                  PREDITO
                NÃ£o  |  Sim
              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        NÃ£o â”‚  TN  â”‚  FP  â”‚
REAL        â”‚      â”‚      â”‚
        Sim â”‚  FN  â”‚  TP  â”‚
              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

### **Legenda:**
- **TP (True Positive):** Acertou o SIM âœ…
- **TN (True Negative):** Acertou o NÃƒO âœ…
- **FP (False Positive):** Erro - Disse SIM (era NÃƒO) âŒ *Alarme Falso*
- **FN (False Negative):** Erro - Disse NÃƒO (era SIM) âŒ *Perdeu o alvo*

---

## ğŸ§® **CÃ¡lculo das MÃ©tricas (Exemplo Titanic)**

### **Matriz de ConfusÃ£o Real:**

```
           PREDITO
         Morreu | Sobreviveu
       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Morreu â”‚   95   â”‚    10     â”‚ = 105 mortos
       â”‚  (TN)  â”‚   (FP)    â”‚
       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Sobre- â”‚   26   â”‚    47     â”‚ = 73 sobreviventes
viveu  â”‚  (FN)  â”‚   (TP)    â”‚
       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         121       57
```

### **Resultados:**

```python
TP = 47  # Acertou: Sobreviveu
TN = 95  # Acertou: Morreu
FP = 10  # Erro: Disse sobreviveu (mas morreu)
FN = 26  # Erro: Disse morreu (mas sobreviveu)

# ACCURACY = 80%
(47 + 95) / 178 = 142 / 178 = 0.798
"8 em cada 10 prediÃ§Ãµes corretas"

# PRECISION = 82.5%
47 / (47 + 10) = 47 / 57 = 0.825
"Quando disse 'sobreviveu', acertou 82.5%"

# RECALL = 64.4%
47 / (47 + 26) = 47 / 73 = 0.644
"Encontrou 64% dos sobreviventes reais"

# F1-SCORE = 72.4%
2 Ã— (0.825 Ã— 0.644) / (0.825 + 0.644) = 0.724
"EquilÃ­brio razoÃ¡vel entre Precision e Recall"
```

---

## ğŸ“Š **Quando Usar Cada MÃ©trica?**

### **1. ACCURACY - AcurÃ¡cia**

**Quando usar:**
âœ… Dados balanceados (50% sim, 50% nÃ£o)
âœ… VisÃ£o geral de performance

**Quando NÃƒO usar:**
âŒ Dados desbalanceados (90% sim, 10% nÃ£o)

**Exemplo de problema:**
```python
# Dataset: 95 pessoas saudÃ¡veis, 5 doentes
# Modelo preguiÃ§oso: "Todo mundo Ã© saudÃ¡vel"

Accuracy = 95/100 = 95%  # Parece Ã³timo!
# Mas errou TODAS as 5 pessoas doentes! âŒ
```

---

### **2. PRECISION - PrecisÃ£o**

**Quando usar:**
âœ… **Custo de FALSO POSITIVO Ã© alto**

**Exemplos prÃ¡ticos:**

```
ğŸ“§ Filtro de SPAM:
- Falso Positivo = Email importante vai pro spam
- Precision alta = Confio que spam Ã© realmente spam

ğŸ¥ DiagnÃ³stico de doenÃ§a grave:
- Falso Positivo = Pessoa saudÃ¡vel recebe tratamento pesado
- Precision alta = Evita tratamentos desnecessÃ¡rios

âš–ï¸ Sistema judicial:
- Falso Positivo = Inocente condenado
- Precision alta = "Melhor 10 culpados soltos que 1 inocente preso"
```

---

### **3. RECALL - RevocaÃ§Ã£o**

**Quando usar:**
âœ… **Custo de FALSO NEGATIVO Ã© alto**

**Exemplos prÃ¡ticos:**

```
ğŸ¥ DiagnÃ³stico de cÃ¢ncer:
- Falso Negativo = Doente nÃ£o Ã© identificado
- Recall alto = CRUCIAL! NÃ£o podemos perder ninguÃ©m

ğŸ” Detector de fraude:
- Falso Negativo = Fraude passa despercebida
- Recall alto = Pegar todas as fraudes possÃ­veis

ğŸš¨ Sistema de seguranÃ§a:
- Falso Negativo = Intruso nÃ£o detectado
- Recall alto = Detectar todas as ameaÃ§as
```

---

### **4. F1-SCORE**

**Quando usar:**
âœ… Comparar mÃºltiplos modelos
âœ… Dados desbalanceados
âœ… NÃ£o sabe qual Ã© mais importante (Precision ou Recall)

**InterpretaÃ§Ã£o:**

```
Modelo A: Precision=90%, Recall=50% â†’ F1=64%
Modelo B: Precision=70%, Recall=70% â†’ F1=70% âœ… Melhor!
Modelo C: Precision=50%, Recall=90% â†’ F1=64%
```

---

## âš–ï¸ **Trade-off: Precision vs Recall**

### **CenÃ¡rio 1: Modelo Conservador**
```python
# SÃ³ diz "SIM" quando TEM CERTEZA

Precision: â†‘ 95% (quase sempre acerta)
Recall:    â†“ 40% (perde muitos casos)
F1:        â†“ 56% (desbalanceado)
```

### **CenÃ¡rio 2: Modelo Agressivo**
```python
# Diz "SIM" na dÃºvida

Recall:    â†‘ 90% (encontra quase todos)
Precision: â†“ 60% (muitos falsos alarmes)
F1:        â†“ 72% (desbalanceado)
```

### **CenÃ¡rio 3: Modelo Equilibrado**
```python
# Balanceado

Precision: 75%
Recall:    75%
F1:        75% âœ… Melhor equilÃ­brio!
```

---

## ğŸ¯ **Confiabilidade de Modelos**

### **Escala de Accuracy:**

| Accuracy | AvaliaÃ§Ã£o | Contexto |
|----------|-----------|----------|
| **< 60%** | âŒ **Ruim** | Pior que "chutar" |
| **60-70%** | ğŸ˜ **Mediano** | Aprendeu algo, mas fraco |
| **70-80%** | âœ… **Bom** | Ãštil para produÃ§Ã£o |
| **80-90%** | ğŸ”¥ **Muito Bom** | Alta confiabilidade |
| **90-95%** | ğŸ† **Excelente** | Estado da arte |
| **> 95%** | âš ï¸ **Suspeito** | Pode ser overfitting |

---

## ğŸš¢ **AnÃ¡lise: Modelo Titanic (79% Accuracy)**

### **Baseline de ComparaÃ§Ã£o:**

```python
# EstratÃ©gia 1: Sempre diz "morreu"
baseline_1 = 61.6% accuracy
# Seu modelo: +17.4% melhor! âœ…

# EstratÃ©gia 2: Chute aleatÃ³rio (50/50)
baseline_2 = 50% accuracy
# Seu modelo: +29% melhor! âœ…
```

### **ComparaÃ§Ã£o Kaggle:**

```
ğŸ† 1Âº lugar:  85.0% accuracy
ğŸ¥ˆ Top 100:   83-84%
ğŸ¥‰ Top 500:   81-82%
ğŸ“Š MÃ©dia:     79-80% â† VOCÃŠ ESTÃ AQUI! âœ…
ğŸ˜ BÃ¡sico:    75-78%
âŒ Fraco:     < 75%
```

### **Limite TeÃ³rico:**

```
âš ï¸ Limite prÃ¡tico: ~85-86%
   (Dados incompletos, sorte/acaso, info perdida)

ğŸ† Recorde Kaggle: ~85%

ğŸ“Š Seu modelo: 79% â†’ 93% do limite teÃ³rico! âœ…
```

### **AvaliaÃ§Ã£o Final:**

```
Accuracy:  79%  âœ… BOM (acima da mÃ©dia)
Precision: 82%  âœ… BOM (confiÃ¡vel quando diz "sim")
Recall:    64%  ğŸ˜ MÃ‰DIO (perde alguns sobreviventes)
F1-Score:  72%  âœ… RAZOÃVEL (equilÃ­brio OK)

ClassificaÃ§Ã£o: MODELO CONSERVADOR
- Prefere nÃ£o arriscar
- Alta Precision (82%) > Recall (64%)
- SÃ³ diz "sobreviveu" com certeza
```

---

## ğŸ” **Confiabilidade de Features**

### **Caso: `sex` no Titanic**

**Por que `sex` foi a feature mais importante (45% importance)?**

âœ… **PolÃ­tica real:** "Mulheres e crianÃ§as primeiro"
âœ… **DiferenÃ§a massiva:** 74% mulheres vs 19% homens sobreviveram (55% gap!)
âœ… **Documentado:** Registros histÃ³ricos
âœ… **Consistente:** Vale em todas as classes

**EstatÃ­sticas:**
```
Mulheres:  74% sobreviveram (233 de 314)
Homens:    19% sobreviveram (109 de 577)

DiferenÃ§a: 55 pontos percentuais! ğŸ”¥

ComparaÃ§Ã£o:
sex_numeric Ã— survived:  -0.54  (FORTE)
pclass Ã— survived:       -0.34  (MODERADA)
fare Ã— survived:         +0.26  (FRACA)
```

### **Checklist de Confiabilidade de Features:**

```
âœ… Faz sentido causal? (nÃ£o Ã© sÃ³ correlaÃ§Ã£o)
âœ… Documentado/explicÃ¡vel? (tem evidÃªncia)
âœ… Consistente em subgrupos? (nÃ£o Ã© flutuaÃ§Ã£o)
âœ… Magnitude forte? (diferenÃ§a significativa)
âœ… Ã‰tico usar? (nÃ£o perpetua discriminaÃ§Ã£o)
```

### **Quando Desconfiar:**

âŒ **CorrelaÃ§Ã£o espÃºria** (causa comum escondida)
âŒ **DiscriminaÃ§Ã£o histÃ³rica** (bias nos dados)
âŒ **Causalidade inversa** (direÃ§Ã£o errada)
âŒ **NÃ£o generalizÃ¡vel** (contexto especÃ­fico)

---

## ğŸ“‹ **Benchmarks por Contexto**

### **Quando 79% Ã© BOM:**

```
âœ… AnÃ¡lises histÃ³ricas (Titanic)
âœ… RecomendaÃ§Ãµes (Netflix, Spotify)
âœ… Filtros de spam (nÃ£o crÃ­tico)
âœ… SegmentaÃ§Ã£o de clientes
âœ… PrevisÃ£o de churn (nÃ£o urgente)
```

### **Quando 79% Ã© INSUFICIENTE:**

```
âŒ DiagnÃ³stico mÃ©dico crÃ­tico (mÃ­nimo: 95-98%)
âŒ Carros autÃ´nomos (mÃ­nimo: 99.9%)
âŒ DetecÃ§Ã£o de fraude (mÃ­nimo: 98-99%)
âŒ Reconhecimento facial seguranÃ§a (mÃ­nimo: 99%)
```

---

## ğŸš€ **Como Melhorar Accuracy**

### **EstratÃ©gias Testadas (Kaggle):**

```python
# 1. Feature Engineering avanÃ§ado (+3-4%)
- Extrair tÃ­tulo do nome (Mr, Mrs, Miss)
- Agrupar cabines por deck
- Criar "famÃ­lia grande" (>4 pessoas)

# 2. Modelos mais complexos (+2-3%)
- Random Forest (ensemble)
- XGBoost (gradient boosting)
- Voting Classifier

# 3. Hyperparameter Tuning (+1-2%)
- GridSearchCV
- RandomizedSearchCV

# 4. Tratamento de outliers (+1%)
- Remover extremos de fare
- Normalizar idade

# 5. Ensemble (+2%)
- Combinar previsÃµes de mÃºltiplos modelos
```

**Ganho esperado total:** 79% â†’ 82-85% (+3-6%)

---

## ğŸ’¡ **DecisÃµes PrÃ¡ticas**

### **Modelo Titanic (79%) Ã© confiÃ¡vel para:**

âœ… **AnÃ¡lise histÃ³rica:**
- Entender padrÃµes de sobrevivÃªncia
- Identificar fatores importantes
- Gerar insights (classe social > idade)
- Validar hipÃ³teses histÃ³ricas

âŒ **DecisÃµes reais (resgate moderno):**
- 21% de erro Ã© inaceitÃ¡vel
- Protocolos mudaram (igualdade)
- Contexto diferente (tecnologia)

---

## ğŸ“Š **ComparaÃ§Ã£o com Outros Datasets**

| Dataset | Problema | Accuracy TÃ­pica | Dificuldade |
|---------|----------|-----------------|-------------|
| **Iris** | 3 espÃ©cies flores | 95-98% | FÃ¡cil |
| **Titanic** | SobrevivÃªncia | **75-85%** | **MÃ©dio** |
| **Wine** | Qualidade vinho | 85-90% | MÃ©dio |
| **Breast Cancer** | DiagnÃ³stico | 95-98% | MÃ©dio-DifÃ­cil |
| **MNIST** | DÃ­gitos escritos | 98-99% | MÃ©dio |
| **ImageNet** | 1000 objetos | 70-80% | DifÃ­cil |

**Titanic Ã© considerado INTERMEDIÃRIO.**

---

## ğŸ“ **Resumo Executivo**

### **Seu Modelo Titanic:**

```
âœ… Accuracy: 79% (BOM - acima da mÃ©dia)
âœ… Na mÃ©dia Kaggle (79-80%)
âœ… 93% do limite teÃ³rico (~85%)
âœ… ConfiÃ¡vel para anÃ¡lise histÃ³rica
âœ… Feature principal (`sex`) Ã© legÃ­tima e documentada
âŒ Insuficiente para decisÃµes crÃ­ticas
```

### **Aprendizados Principais:**

1. **MÃ©tricas diferentes para contextos diferentes**
   - Accuracy â‰  Precision â‰  Recall
   - F1-Score balanceia ambos

2. **Confiabilidade Ã© contextual**
   - 79% pode ser Ã³timo ou pÃ©ssimo
   - Depende do problema e consequÃªncias

3. **Questionar features Ã© fundamental**
   - CorrelaÃ§Ã£o â‰  CausaÃ§Ã£o
   - Buscar evidÃªncias e contexto

4. **Trade-offs sÃ£o inevitÃ¡veis**
   - Precision â†‘ â†’ Recall â†“
   - Escolher baseado no custo de erros

---

## âœ… **Checklist de AvaliaÃ§Ã£o de Modelo**

### **Performance:**
- [ ] Accuracy > baseline (estratÃ©gias simples)
- [ ] Comparou com benchmarks do problema
- [ ] F1-Score balanceado (se dados desbalanceados)
- [ ] Testou em dados separados (nÃ£o treino)

### **Confiabilidade:**
- [ ] Features fazem sentido causal
- [ ] Magnitude de diferenÃ§a Ã© significativa
- [ ] Consistente em subgrupos
- [ ] NÃ£o perpetua discriminaÃ§Ã£o

### **InterpretaÃ§Ã£o:**
- [ ] Entende o que modelo estÃ¡ aprendendo
- [ ] Sabe limitaÃ§Ãµes e contexto
- [ ] Identifica possÃ­veis vieses
- [ ] Documenta decisÃµes

---

**ğŸ‰ ParabÃ©ns! VocÃª dominou:**
- âœ… As 4 mÃ©tricas essenciais
- âœ… InterpretaÃ§Ã£o de resultados
- âœ… AvaliaÃ§Ã£o crÃ­tica de modelos
- âœ… Pensamento contextual

**ğŸš€ PrÃ³ximo passo: Dia 2 - API REST com esse modelo!**
